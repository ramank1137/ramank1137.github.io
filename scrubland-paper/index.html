<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Scrubland–Farm–Plantation Paper | Raman Kumar </title> <meta name="author" content="Raman Kumar"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ramank1137.github.io/scrubland-paper/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Raman Kumar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Scrubland–Farm–Plantation Paper</h1> <p class="post-description"></p> </header> <article> <hr> <p>layout: page title: “Distinguishing Scrublands, Farms, and Plantations Across India” description: “Motivation and methodology for our multi-resolution LULC mapping framework using high-resolution CV-derived ground truth.” date: 2025-11-28 10:00:00 +0530 categories: [research] tags: [lulc, scrubland, agriculture, plantations, remote-sensing] permalink: /blog/lulc-v4-methodology/ —</p> <p><strong>Authors:</strong><br> Raman Kumar, Aatif Dar, Aaditeshwar Seth<br> <em>Department of Computer Science, IIT Delhi</em></p> <hr> <h1 id="introduction">Introduction</h1> <p>Scrublands are ecologically and socially important landscapes in India, supporting biodiversity, groundwater recharge, and pastoral livelihoods. Yet they are often misclassified as wastelands, causing them to be overlooked in restoration and land-management programs. A major challenge is that scrublands and rain-fed agricultural fields exhibit <strong>very similar spectral and seasonal patterns</strong>, making them difficult to distinguish in existing global LULC datasets.</p> <p>Similarly, plantations pose an additional difficulty because most global and national datasets merge them into generic tree or agricultural classes. This affects assessments related to deforestation, afforestation drives, and cropping-intensity measurements.</p> <p>These problems exist largely due to the <strong>lack of high-quality, India-specific labeled datasets</strong> for scrublands, farms, and plantations. Models trained few global datasets using medium-resolution imagery struggle to capture India’s fragmented agro as well as non-agro(scrublands, plantations, etc) landscapes.</p> <p>To address this, our paper develops a generalized <strong>computer-vision-based methodology</strong> that uses <strong>high-resolution (1 m) imagery</strong> to automatically generate large-scale, high-quality training samples. We used this approach to generate samples for farms, scrublands, and plantations. These samples are then used to train improved classifiers at 10 m using Googles satelite embeddings v1, enabling more accurate differentiation and creating India’s first nationwide plantation layer.<br> <em><a href="https://ramank1137.github.io/assets/pdf/Scrubland_vs_Farmland_vs_Plantation.pdf">Paper draft</a></em></p> <hr> <h1 id="methodology-overview">Methodology Overview</h1> <p>The workflow consists of <strong>five sequential components</strong>, shown in Figure 1 of the paper.</p> <blockquote> <p><strong>Figure Placeholder:</strong><br> <em>Insert Figure 1: Complete pipeline overview.</em></p> </blockquote> <hr> <h1 id="1-spatial-representativeness-and-tile-selection">1. Spatial Representativeness and Tile Selection</h1> <p>Each Agro-Ecological Zone (AEZ) is divided into a set of grids:</p> <p>[ G = { g_1, g_2, \dots, g_N } ]</p> <p>where each grid corresponds to a 9 km × 9 km region containing 32×32 high-resolution tiles.</p> <p>For every grid ( g_i ), we compute a normalized feature distribution ( P_i ) using clusters derived from Google’s 64-dimensional embeddings. The objective is to select a subset:</p> <p>[ S \subset G, \quad |S| = p ]</p> <p>such that the aggregated distribution:</p> <p>[ P_S = \frac{1}{|S|} \sum_{g_i \in S} P_i ]</p> <p>approximates the AEZ-level distribution:</p> <p>[ P_{\text{AEZ}} = \frac{1}{N} \sum_{g_i \in G} P_i ]</p> <p>Selection is driven by minimizing the <strong>Jensen–Shannon divergence</strong>:</p> <p>[ D_{JS}(P \parallel Q) = \frac{1}{2} D_{KL}(P \parallel M) + \frac{1}{2} D_{KL}(Q \parallel M), \quad M = \frac{1}{2}(P+Q) ]</p> <p>At each step, the grid added is:</p> <p>[ g^* = \arg\min_{g_i \in G \setminus S} D_{JS}\left( P_{\text{AEZ}} \parallel P_{S \cup {g_i}} \right) ]</p> <p>Approximately <strong>3% of grids per AEZ</strong> are selected. These are subdivided into 16×16 sub-grids for high-resolution processing.</p> <hr> <h1 id="2-high-resolution-boundary-delineation">2. High-Resolution Boundary Delineation</h1> <p>High-resolution imagery (zoom level 17) is downloaded for each representative block. Two computer-vision pipelines operate on these tiles:</p> <h2 id="21-farm--non-agricultural-boundaries">2.1 Farm &amp; Non-Agricultural Boundaries</h2> <p>We apply a <strong>FracTAL-ResUNet</strong> model (following Wang et al.) that predicts:</p> <ul> <li>field extent</li> <li>boundary probability</li> <li>distance-to-boundary</li> </ul> <p>Because the model outputs probability maps, <strong>hierarchical watershed segmentation</strong> is used to obtain closed polygons over the stitched 16×16 outputs.</p> <p>For each boundary, we compute:</p> <h3 id="entropy"><strong>Entropy</strong></h3> <p>Local Shannon entropy over grayscale neighborhoods:</p> <p>[ H = -\sum_{i=1}^L p_i \log_2(p_i) ]</p> <p>Segment-level entropy:</p> <p>[ \overline{H}<em>S = \frac{1}{|S^+|} \sum</em>{x \in S^+} H(x) ]</p> <h3 id="rectangularity"><strong>Rectangularity</strong></h3> <p>[ R = \frac{A_{\text{contour}}}{A_{\text{rect}}} ]</p> <h3 id="size"><strong>Size</strong></h3> <p>Pixel-area of the segment.</p> <h2 id="22-plantation-boundaries">2.2 Plantation Boundaries</h2> <p>Plantations are detected using a <strong>fine-tuned YOLO model</strong>, retaining only high-confidence detections.</p> <hr> <h1 id="3-rule-based-boundary-refinement">3. Rule-Based Boundary Refinement</h1> <p>High-confidence segments are identified using rules defined in the paper.</p> <h2 id="farm-rules"><strong>Farm rules:</strong></h2> <ul> <li>Entropy &lt; <strong>1.0</strong> </li> <li>Rectangularity &gt; <strong>0.67</strong> </li> <li>Size between <strong>500–2000 m²</strong> </li> <li>Must be part of a cluster of <strong>≥ 3</strong> farms</li> </ul> <h2 id="scrubland--non-agro-rules"><strong>Scrubland / non-agro rules:</strong></h2> <ul> <li>Size <strong>60,000–5,000,000 m²</strong> </li> <li> <blockquote> <p>50% non-agricultural pixels (via IndiaSAT v3 cross-check)</p> </blockquote> </li> </ul> <h2 id="plantation-rules"><strong>Plantation rules:</strong></h2> <ul> <li>Size <strong>1,000–20,000 m²</strong> </li> </ul> <h2 id="overlap-resolution"><strong>Overlap resolution:</strong></h2> <p>[ \text{Plantation} &gt; \text{Farm} &gt; \text{Scrubland} ]</p> <hr> <h1 id="4-sample-generation-and-classifier-training">4. Sample Generation and Classifier Training</h1> <p>From refined boundaries, ~150 uniformly distributed samples per class are extracted for each 16×16 block.</p> <p>For each sample, <strong>Google’s 64-dimensional embedding vectors</strong> for the <strong>past three years</strong> are collected.</p> <p>A <strong>Random Forest classifier</strong> is trained <strong>per AEZ</strong>, allowing the model to adapt to regional conditions and avoid over-generalization. These models produce farm, non-agro, and plantation predictions at <strong>10 m resolution</strong>.</p> <hr> <h1 id="5-integration-into-indiasat">5. Integration into IndiaSAT</h1> <p>The AEZ-level predictions are integrated into the IndiaSAT v3 LULC pipeline:</p> <ol> <li>Add built-up, water, barren classes.</li> <li>Insert classifier outputs (farm, non-agro, plantation).</li> <li>Split farm regions into four crop-intensity classes (8, 9, 10, 11).</li> <li>Split non-agro regions into forest and non-forest; non-forest becomes <strong>scrubland (12)</strong>.</li> <li>Assign plantation as <strong>class 13</strong>.</li> </ol> <hr> <h1 id="conclusion">Conclusion</h1> <p>This methodology enables accurate, large-scale differentiation of scrublands, farms, and plantations across India by leveraging high-resolution CV-derived boundaries and AEZ-specific classification. It also introduces India’s first dedicated nationwide plantation layer and improves the contextual relevance of LULC mapping across diverse landscapes.</p> <hr> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Raman Kumar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>