<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Distinguishing Scrublands, Farms, and Plantations Across India | Raman Kumar </title> <meta name="author" content="Raman Kumar"> <meta name="description" content="Motivation and methodology for our multi-resolution LULC mapping framework using high-resolution CV-derived ground truth."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ramank1137.github.io/scrubland-paper/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Raman Kumar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Distinguishing Scrublands, Farms, and Plantations Across India</h1> <p class="post-description">Motivation and methodology for our multi-resolution LULC mapping framework using high-resolution CV-derived ground truth.</p> </header> <article> <p><strong>Authors:</strong><br> Raman Kumar, Aatif Dar, Aaditeshwar Seth<br> <em>Department of Computer Science, IIT Delhi</em></p> <p>We generated pan-India LULC v4 layers from 2017-2018 to 2023-2024 which can be checked on our application. <a href="https://raman-461708.projects.earthengine.app/view/pan-india-lulc-indiasat-v4" rel="external nofollow noopener" target="_blank">Link to application</a>. Our open source code is available on this link. <a href="https://github.com/ramank1137/Scrubland-Field-Delineation" rel="external nofollow noopener" target="_blank">Link to code</a></p> <blockquote> <div style="background:white; padding:10px; display:block; text-align:center;"> <img src="/assets/img/Google-app.png" alt="Pipeline" style="max-width:100%; height:auto;"> </div> <p>Figure shows our application which can be accessed from the above link.</p> </blockquote> <h1 id="introduction">Introduction</h1> <p>Scrublands are ecologically and socially important landscapes in India, supporting biodiversity, groundwater recharge, and pastoral livelihoods. Yet they are often misclassified as wastelands, causing them to be overlooked in restoration and land-management programs. A major challenge is that scrublands and rain-fed agricultural fields exhibit <strong>very similar spectral and seasonal patterns</strong>, making them difficult to distinguish in existing global LULC datasets.</p> <p>Similarly, plantations pose an additional difficulty because most global and national datasets merge them into generic tree or agricultural classes. This affects assessments related to deforestation, afforestation drives, and cropping-intensity measurements.</p> <p>These problems exist largely due to the <strong>lack of high-quality, India-specific labeled datasets</strong> for scrublands, farms, and plantations. Models trained few global datasets using medium-resolution imagery struggle to capture India’s fragmented agro as well as non-agro(scrublands, plantations, etc) landscapes.</p> <p>To address this, our paper develops a generalized <strong>computer-vision-based methodology</strong> that uses <strong>high-resolution (1 m) imagery</strong> to automatically generate large-scale, high-quality training samples. We used this approach to generate samples for farms, scrublands, and plantations. These samples are then used to train improved classifiers at 10 m using Googles satelite embeddings v1, enabling more accurate differentiation and creating India’s first nationwide plantation layer.<br> <em><a href="https://ramank1137.github.io/assets/pdf/Scrubland_vs_Farmland_vs_Plantation.pdf">Paper draft</a></em></p> <h1 id="methodology-overview">Methodology Overview</h1> <p>The workflow contains <strong>five sequential components</strong>, summarized below.</p> <blockquote> <div style="background:white; padding:10px; display:block; text-align:center;"> <img src="/assets/img/Pipeline.png" alt="Pipeline" style="max-width:100%; height:auto;"> </div> <p>The figure shows the overview of five module pipeline. (1) Spatial Representativeness and Tile Selection: Select representative AEZ grids using Jensen–Shannon divergence. (2) High-Resolution Boundary Delineation: Extract farm, scrubland, and plantation boundaries using CV models on 1 m imagery. (3) Rule-Based Boundary Refinement: Apply entropy, rectangularity, and size thresholds to retain high-confidence segments. (4) Sample Generation and Classifier Training: Generate samples and train AEZ-specific Random Forest classifiers using 64-dim embeddings. (5) Integration into IndiaSAT: Combine AEZ predictions with IndiaSAT modules to produce final farm, scrubland, and plantation classes.</p> </blockquote> <h1 id="1-spatial-representativeness-and-tile-selection">1. Spatial Representativeness and Tile Selection</h1> <p>Each Agro-Ecological Zone (AEZ) is divided into grids:</p> \[G = \{ g_1, g_2, \dots, g_N \}\] <p>For each grid $g_i$, a normalized feature distribution $P_i$ is derived from clusters of Google’s 64-dimensional embeddings.</p> <p>The task is to select a subset:</p> \[S \subset G, \quad |S| = p\] <p>such that its aggregated distribution:</p> \[P_S = \frac{1}{|S|} \sum_{g_i \in S} P_i\] <p>approximates the AEZ-level distribution:</p> \[P_{\text{AEZ}} = \frac{1}{N} \sum_{g_i \in G} P_i\] <p>Selection minimizes the <strong>Jensen–Shannon (JS) divergence)</strong>:</p> \[D_{JS}(P \parallel Q) = \frac{1}{2} D_{KL}(P \parallel M) + \frac{1}{2} D_{KL}(Q \parallel M), \quad M = \frac{1}{2}(P + Q)\] <p>At each iteration:</p> \[g^* = \arg\min_{g_i \in G \setminus S} D_{JS} \Bigl( P_{\text{AEZ}} \parallel P_{S \cup \{ g_i \}} \Bigr)\] <p>Approximately <strong>3% of grids per AEZ</strong> are selected and subdivided into 16×16 sub-grids.</p> <blockquote> <div style="background:white; padding:10px; display:block; text-align:center;"> <img src="/assets/img/Representative-tile.png" alt="Pipeline" style="max-width:100%; height:auto;"> </div> <p>Figure showing representative tile selection across India. a) India divided into agro-ecological zones (AEZs) b) Next for each AEZ representative tiles are selected. Here we show for AEZ 7. Below the grids, clusters are shown whic hare generated from Google embeddings v1 using k-means clustering (k=32). Then the tiles are selected in orange using Jensen-Shannon (JS) divergence. c) Similary representative tiles are selected from all of India which will capture all the nuances of different landscapes across all the AEZs.</p> </blockquote> <h1 id="2-high-resolution-boundary-delineation">2. High-Resolution Boundary Delineation</h1> <p>High-resolution imagery (zoom 17) is downloaded for each selected block.</p> <p>Two CV pipelines operate on these tiles:</p> <h2 id="21-farm--non-agricultural-boundaries">2.1 Farm &amp; Non-Agricultural Boundaries</h2> <p>We use the approach by wang et al. who uses <strong>FracTAL-ResUNet</strong> model to generate:</p> <ul> <li>field extent</li> <li>boundary probability</li> <li>distance-to-boundary</li> </ul> <p>These outputs are merged and processed by <strong>hierarchical watershed segmentation</strong> to obtain closed polygons.</p> <p>For delineation of farm and scrubland boundaries, I extended the approach of Wang et al. (2022), which uses high-resolution imagery for field extraction but does not separate fields from adjacent scrublands. We generalized this method to mixed landscapes by leveraging the insight that unlike naturally shaped scrublands, agricultural fields exhibit lower geometric and textural randomness which can be captured via entropy, rectangularity, and segment-size metrics. Now to seperate out the boundaries of farms and non-agro regions which will include scrublands we compute the following for each segement which will be used in the following module to seperate out farms and non-agro from the boundaries generated:</p> <h4 id="entropy">Entropy</h4> \[H = - \sum_{i=1}^{L} p_i \log_2(p_i)\] <p>Segment-level entropy:</p> \[\overline{H}_S = \frac{1}{|S^+|} \sum_{x \in S^+} H(x)\] <h4 id="rectangularity">Rectangularity</h4> \[R = \frac{A_{\text{contour}}}{A_{\text{rect}}}\] <h4 id="size">Size</h4> <p>Computed as pixel-area of the segment.</p> <h2 id="22-plantation-boundaries">2.2 Plantation Boundaries</h2> <p>For plantations, we fine-tuned a YOLO detection model to identify plantations across heterogeneous landscapes at the same spatial resolution. To train this model, we curated sparse ground truth from multiple regions and expanded it using augmentation techniques like cut-mix.</p> <h1 id="3-rule-based-boundary-refinement">3. Rule-Based Boundary Refinement</h1> <p>To refine the boundaries and filter out high-confidence segments for farms, non-agro(including scrubs) and plantation we identified follwing rules.</p> <h2 id="farm-rules">Farm rules</h2> <ul> <li> <blockquote> <p>Entropy &lt; 1.0</p> </blockquote> </li> <li> <blockquote> <p>Rectangularity &gt; 0.67</p> </blockquote> </li> <li> <blockquote> <p>Size ∈ [500, 2000] m²</p> </blockquote> </li> <li> <blockquote> <p>Must belong to a cluster of ≥ 3 farms</p> </blockquote> </li> </ul> <h2 id="scrubland--non-agro-rules">Scrubland / non-agro rules</h2> <ul> <li> <blockquote> <p>Size ∈ [60,000, 5,000,000] m²</p> </blockquote> </li> <li> <blockquote> <p>50% non-agricultural pixels (via IndiaSAT v3)</p> </blockquote> </li> </ul> <h2 id="plantation-rules">Plantation rules</h2> <ul> <li> <blockquote> <p>Size ∈ [1,000, 20,000] m²</p> </blockquote> </li> </ul> <h2 id="overlap-hierarchy">Overlap hierarchy</h2> \[\text{Plantation} &gt; \text{Farm} &gt; \text{Scrubland}\] <h1 id="4-sample-generation-and-classifier-training">4. Sample Generation and Classifier Training</h1> <p>Once we have the high-quality segements, we then generated samples from each of these grids uniformly. For each sample, <strong>Google’s 64-dimensional embeddings</strong> for the <strong>past 3 years</strong> are collected. Using these samples we trained <strong>a pool of classifiers for each AEZ</strong>, allowing regional adaptation and avoiding over-generalization. The resulting models produce farm, non-agro, and plantation predictions at <strong>10 m spatial resolution</strong>.</p> <h1 id="5-integration-into-indiasat">5. Integration into IndiaSAT</h1> <p>The AEZ-level outputs are merged with the IndiaSAT v3 framework:</p> <ol> <li>Add built-up, water, and barren classes</li> <li>Insert farm, non-agro, and plantation predictions</li> <li>Split farms into crop-intensity classes (8, 9, 10, 11)</li> <li>Split non-agro into forest vs. non-forest; non-forest is scrubland (12)</li> <li>Assign plantations as class (13)</li> </ol> <h1 id="conclusion">Conclusion</h1> <p>This methodology enables accurate mapping of scrublands, farms, and plantations across India by combining high-resolution CV-derived boundaries with AEZ-specific modeling. It produces India’s first nationwide plantation layer and significantly improves distinction between scrublands and rain-fed agriculture.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Raman Kumar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>